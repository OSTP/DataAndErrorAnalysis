
%Copyright 2016 R.D. Martin
%This book is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
%
%This book is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details, http://www.gnu.org/licenses/.
\chapter{Statistics - Distributions}
\label{chap:StatsDistributions}
In the previous chapter, we considered a sample of data that consisted of measurements of a certain quantity (e.g. cat length), and defined a few simple variables to describe that sample (e.g. mean, variance). Those were general quantities that can be applied to any sample of measurements.

In many physical situations, the data will follow particular "distributions". That is, if one makes a histogram of the measurements, the shape of that histogram will be well described by a function. Certain physical processes lead to very specific distribution functions, and we will examine two of those in this chapter (the binomial and the Poisson distributions).

\section{The binomial distribution}

The binomial distribution is used to describe the result of an experiment that can go in one of two ways (for example, flipping a coin can be either heads or tails). Very generally, a lot of processes can be thought of as binomial even if there are more than two possible outcomes. If you are interested in the number 5 coming up when rolling a single dice, even though there are 6 possible outcomes, you can think of it as a binomial problem (you either get 5 or you do not).

The binomial distribution describes \textbf{how often we will get $k$ successes in $N$ independent trials, when we expect $pN$ successes}. We call $p$ the probability of getting the "successful" outcome, and reserve a more formal description of probability for a later chapter. For example, if we have a coin and we are interested in the number of times that we get ``heads'', we can think of $k$ as the number of times we get heads in $N$ coin tosses. We can think of $p$ as the fraction of times we get heads (either that we expect or that we measured). If we have a biased coin that, on average, gives 70\% heads, then $p=0.7$ which can be measured by tossing the coin many times and measuring the fraction of time that we get heads (this would be the ``frequentist'' definition of the probability, $p$). 


\begin{example}{}{For an unfair coin that has a $p=0.7$ of being heads on any given toss, what is the probability of obtaining exactly 2 heads in 3 coin tosses?}{}
If we label each toss by H (heads) or T (tails), then there are three possible sequences of 3 tosses that give two heads: HHT, HTH, and THH. The probability of obtaining the first sequence (HHT) is given by:
\begin{align*}
P_{HHT}=pp(1-p)
\end{align*} 
$p$ for the first toss, multiplied by $p$ for the second toss and $(1-p)$ for the third toss. The other two sequences (HTH and THH) have the same probability. We only care about obtaining two heads in three tosses (not the order), so the probability of obtaining two heads in 3 tosses is simply the sum of the (identical) probabilities of obtaining each sequence:
\begin{align*}
P_{2H}&=P_{HHT}+P_{HTH}+P_{THH}=3pp(1-p)\\
&=3\times0.7^2\times0.3=0.441
\end{align*}
Thus, there is a 44.1\% chance that with this biased coin, we would obtain exactly 2 heads in 3 tosses.
\end{example}

A general formula for the probability of obtaining $k$ successes in $N$ trials, when the probability of a success is $p$, can easily be derived.  If there are $k$ successes, then there will be $N-k$ failures. One possible way to obtain this is to have the first $k$ trials be successes, and the next $N-k$ trials be failures. The probability of that particular sequence would be:
\begin{align*}
P_{success\: first}=ppp\dots(1-p)(1-p)=p^k(1-p)^{N-k}
\end{align*}
However, we do not care about the particular order of the successes, so we must think about all of the possible sequences in which we can have $k$ successes in $N$ trials. This is found by the combinatorial formula for ``N choose k'':
\begin{align*}
\left(
\begin{array}{c}
N\\
k\\
\end{array}
\right)=\frac{N!}{k!(N-k)!}
\end{align*}
and corresponds to the number of ways of choosing the $k$ ``positions'' of the successes in a sequence of $N$ trials. The total probability of obtaining exactly $k$ successes in $N$ trials is thus given by multiplying the probability of a single sequence (e.g. $P_{success\: first}$) by the number of possible sequences:
\begin{align}
\label{eqn:binomialP}
P^{binom}(k,N,p)=\frac{N!}{k!(N-k)!}p^k(1-p)^{N-k}
\end{align}
which is called the \textbf{binomial probability} mass function\footnote{Since this is a function of a discrete variable, $k$, we call it a ``probability mass function'' instead of a ``probability density function''.}.

Let us suppose that we run a food stand that sells three different kinds of poutines: a classic poutine, a poutine with pulled pork, and a vegetarian poutine (with vegetarian gravy). Our historical data show that 70\% of customers purchase a classic poutine, 20\% of customers purchase the pork poutine, and 10\% purchase the vegetarian option. It is one hour before closing time and we are running low on pork; we only have enough pork for 5 poutines and want to know if we should send someone to buy more. From our previous data, we also know that in the hour before closing, we should expect about 15 customers. Thus, we can ask ourselves, what is the probability that we will get $k=5$ customers out of $N=15$ customers that order pork poutines in the next hour? Using the binomial distribution, we can easily estimate that quantity to be:
\begin{align*}
P(k=5,N=15,p=0.2)=\frac{N!}{k!(N-k)!}p^k(1-p)^{N-k}=0.103
\end{align*}
There is thus a 10.3\% chance that we will sell exactly 5 pork poutines to the next 15 customers.


However, this is not quite the  information that we need in order to know if we should purchase more pork. We really want to know what the chances are of the next 15 customers purchasing 6 or more pork poutines, in which case we would not have enough pork. So we really need to add the probabilities for people to buy 6 or more pork poutines, to get the probability that we do not have enough pork:
\begin{align*}
P_{Not\: enough}=P(k=6,N=15,p=0.2)+P(k=7,N,p)+\dots+P(k=15,N,p)
\end{align*}
which may be tedious to calculate by hand. An equivalent calculation would be to sum the probabilities of people buying 5 or less poutines, giving the probability that we will have enough pork:
\begin{align*}
P_{Have\: enough}=P(k=0,N=15,p=0.2)+P(k=1,N,p)+\dots+P(k=5,N,p)
\end{align*}
where it should be clear that $P_{Not\: enough}+P_{Have\: enough}=1$.

Fortunately, we do not have to calculate this by hand and can use a simple python program. The code below shows how to calculate the sum, but also illustrates that there are built-in functions to calculate these sums, as they come up very often. The \code{cdf()} functions sums the probabilities of getting $k$ or less, and the \code{sf} function, which is 1-cdf, gives the probability of getting $k$ or higher.
\begin{lstlisting}[frame=single] 
#The binomial distribution
import numpy as np
import pylab as pl
import scipy.stats as stats #for binomial distribution

N=15 # number of customers (trials)
p=0.2 # probability of ordering a pork poutine

print("Prob of exactly 5 pork poutines: {:.3f}".format(stats.binom.pmf(5,N,p)))

#An array to hold all possible outcomes:
allOutcomes=np.arange(0,N+1)
#An array to hold the probabilities corresponding to each outcome:
probOutcomes=stats.binom.pmf(allOutcomes,N,p)

#Can sum the probabilities (or use sf and cdf):
print("Prob of 6 or more (sum): {:.3f}".format(probOutcomes[6:].sum()))
print("Prob of 6 or more (sf): {:.3f}".format(stats.binom.sf(5,N,p)))
print("Prob of 5 or less (sum): {:.3f}".format(probOutcomes[:6].sum()))
print("Prob of 5 or less (cdf): {:.3f}".format(stats.binom.cdf(5,N,p)))

#Make a plot of the probability of each outcome
pl.plot(allOutcomes,probOutcomes,'o',color='black')
pl.xlabel("Number of pork poutines ordered (k)")
pl.ylabel("Prob of ordering")
pl.title("Binomial prob. distribution for N=15, p=0.2")
pl.axis([-1,16,0,0.3])
pl.grid()
pl.show()
\end{lstlisting}
The output of the code is:
\begin{verbatim}
Prob of exactly 5 pork poutines: 0.103
Prob of 6 or more (sum): 0.061
Prob of 6 or more (sf): 0.061
Prob of 5 or less (sum): 0.939
Prob of 5 or less (cdf): 0.939
\end{verbatim}
and we can see that there is 94\% chance that we do not need to purchase more pork (the probability of having 5 or less pork poutine orders is 94\%). In this case, we would probably take the 6\% chance that we will not have enough pork poutines.

We also used the code to create a graph of the probability of $k$ outcomes as a function of $k$ for a fixed value of $N=15$ and $p=0.2$, which is shown in Figure \ref{fig:binomial}. We call this plot a ``distribution'' as it describes the distribution of outcomes that we expect. That is, given the values of $N$ and $p$ for our situation, we can use Figure \ref{fig:binomial} to model how many people purchase pork poutines in the hour preceding the closure of our poutine shop over many nights. For example, we would expect that 23\% of the time, 2 pork poutines will be ordered in the last hour. The most likely number of pork poutines to be ordered in the last hour is 3, which is equal to $pN$ (0.2$\times$15).

\capfig{0.5\textwidth}{figures/binomial.png}{\label{fig:binomial} Binomial distribution for $N=15$ and $p=0.2$.}

We can also turn the problem around and test the hypothesis that customers in our poutine store can be modeled by the binomial distribution. To do this, we could collect data to measure, over many nights, the number of customers that bought pork poutine in the hour preceding the store closing. In order to keep things simple, we should measure the number of pork poutines bought by the last 15 customers, rather than in the last hour (since we would not expect exactly 15 customers in the last hour every time). The data could look like that in table \ref{tab:poutineOrders}.
\begin{table}[h!]
\center
\begin{tabular}{|c|}
\hline \textbf{Number of pork poutines ordered by last 15 customers} \\
\hline
3\\
\hline
2\\
\hline
0\\
\hline
0\\
\hline
3\\
\hline
2\\
\hline
2\\
\hline
3\\
\hline
2\\
\hline
 $\dots$ \\
 \hline
\end{tabular}
\caption{\label{tab:poutineOrders} Sample data on pork poutine orders by the last 15 customers in the store over many nights}
\end{table} 

We can plot a normalized histogram of these numbers and overlay the binomial distribution that we obtained in Figure \ref{fig:binomial} to see if they agree. This is done in Figure \ref{fig:binomial_data} where Table \ref{tab:poutineOrders} was generated with 100 lines (simulating 100 nights of data taking).

\capfig{0.5\textwidth}{figures/binomial_data.png}{\label{fig:binomial_data} Binomial distribution for $N=15$ and $p=0.2$ overlaid with simulated data from 100 measurements of the number of customers out of that bought a pork poutine (simulated with a binomial distribution with $p=0.2$). }

We do not yet have the tools to quantitatively conclude whether the distribution of the data (the histogram) agrees with the predicted distribution from our binomial distribution model, but looking by eye, it does seem that the binomial distribution is a good model for the histogram of the data. As you can see, the histogram itself, when normalized, can be thought of as a probability distribution. With no model, we could generate the histogram using the data, and then use that histogram to make statements about the probability of have between, say, 3 and 4 pork poutine orders. 

\subsection{Statistical properties of the binomial distribution}
The mean of measurements that follow the binomial distribution, $\bar k$, for $N$ trials with probability $p$ of success is given by:
\begin{align}
\bar k = \sum_{k=0}^{k=N}kP^{binom}(k,N,p)=Np
\end{align}
and their variance is given by:
\begin{align}
\sigma^2 = \sum_{k=0}^{k=N}(k-\bar k)^2P^{binom}(k,N,p)=Np(1-p)
\end{align}

Thus, a simple way to test if a set of measurements are binomially distributed is to calculate their mean and variance to see if they agree with that expected from the binomial distribution.

\begin{example}{}{In a class of 20 students, we have counted over 15 different lectures how many of the students checked their smart phone instead of paying attention to class. Over the 15 different lectures, the following number of students checked their phone: \{8,10,7,6,5,9,5,4,4,5,6,4,5,7,6\}. For example, in the first lecture, 8 out 20 students checked their phone, in the second lecture, 10 students checked their phone, etc. Use some simple statistics to determine whether the number of students checking their phone during a given lecture is consistent with being binomially distributed.}{}
\label{ex:BinomialPhones}
We wish to check that the number of students who check their phone follows a binomial distribution. In each lecture, we have $N=20$ students and we thus wish to see if we can predict, on average, how many of those students will check their phone. We first need to determine the probability of checking their phone, $p$, which we must estimate from the data. We can estimate $p$ by averaging the fraction of students that check their phone at each lecture. We can then compare the mean and variance of the data with what we expect for a binomial distribution with the value of $p$ that we estimated. We can also compare the histogram of the data with the analytical prediction from the binomial probability mass function.

This is shown in the following python code:
\begin{lstlisting}[frame=single] 
#Example 6-2
import numpy as np
import scipy.stats as stats
#N is the number of students
N=20
#put the data into an array, this is the number, k, during each experiment
xi=np.array([8,10,7,6,5,9,5,4,4,5,6,4,5,7,6])
#get the average (mean) value of xi/N, which is our estimate of p
p=np.mean(xi/N)
print("p is {:.2f}".format(p))
#We can now compare the mean and variance of the data with what we expect 
#for the binomial distribution:
print("data mean: {:.1f}, data variance: {:.1f}".format(xi.mean(),xi.var(ddof=1)))
print("binom. mean: {:.1f}, binom. variance: {:.1f}".format(N*p,N*p*(1-p)))

#Let's also compare this using a histogram
binedges=np.linspace(-0.5,N+0.5,N+2)
pl.hist(xi,bins=binedges,normed=True,color='grey',alpha=0.5,label='data')
#An array to hold all possible outcomes:
allOutcomes=np.arange(0,N+1)
#An array to hold the probabilities corresponding to each outcome:
probOutcomes=stats.binom.pmf(allOutcomes,N,p)
pl.plot(allOutcomes,probOutcomes,'o-',color='black',label='analytical binom. prob.')
pl.xlabel("number of students checking phone")
pl.ylabel("Prob of checking phone")
pl.title("Comparison of data and binom. prob. for N={}, p={:.2f}".format(N,p))
pl.legend()
pl.show()
\end{lstlisting}
The output is:
\begin{verbatim}
p is 0.30
data mean: 6.1, data variance: 3.4
binom. mean: 6.1, binom. variance: 4.2
\end{verbatim}
The mean from the data and that predicted for a binomial distribution agree exactly, and the variances are difficult to compare without uncertainties, although they appear to be consistent. We should not be surprised that the mean from the binomial prediction is exactly equal to the mean from the data, since we used the data to evaluate $p$ in such a way that $Np$ is precisely equal to the mean of the data!

Figure \ref{fig:binomial_studentdata} shows a comparison of the data plotted into a normalized histogram and the prediction from the binomial distribution.

\capfig{0.5\textwidth}{figures/binomial_studentdata.png}{\label{fig:binomial_studentdata} Binomial distribution for $N=20$ and $p=0.3$ overlaid with the data of 15 lectures where the number of students (out of 20) checking their phone is plotted. }

In order to make a definitive statement, we would need more data to see if the variance of the data converges to that predicted for a binomial distribution and to see if the histogram of the data approaches the known distribution. If we had other competing models that also predicted a variance, we could see which model predicts the closest variance. Ultimately, it is very difficult to confirm if data come from a specific distribution if there are few data points.
\end{example}

\section{The Poisson distribution}
The Poisson distribution is used to predict \textbf{the probability of observing $k$ successes when we expect $n$}. One can show that the Poisson distribution is the limiting case of the binomial distribution when $N$ is very large and $p$ is very small, but $Np$ (the mean of the binomial distribution) is finite (see Figure \ref{fig:poisson_binom}). The $n$ in the Poisson distribution is equal to $Np$ from the binomial distribution, which is the mean of the binomial distribution. The Poisson probability mass function is given by:
\begin{align*}
 P(k,n)=\frac{n^k e^{-n}}{k!} 
\end{align*}  
and is much easier to calculate than the binomial distribution. The Poisson distribution is said to apply to ``rare processes'', as the probability, $p$, of a success occurring is small. Note that the Poisson distribution only has one parameter, $n$, the expected number of successes. 

One common example is to predict the expected number of radioactive decays in a period of time, $t$, for a given radioactive decay process with ``time constant'' $\lambda$. Generally, we would have a large number of atoms, $N$, and the probability of a particular atom to decay, $p$, is very small. However, the average number of decays in a certain time interval, $Np$ is finite. We could model this with a binomial distribution, but the Poisson distribution is in this case a very good approximation, and much easier to calculate. In fact, for a process with radioactive decay, $N$ would be of order Avogadro's number $10^{23}$, and taking the factorial of such a large number (as in \ref{eqn:binomialP}) is not practical.

Recall, the radioactive decay law , which tells us how many un-decayed atoms we should have at time t, $N(t)$, if we started with $N_0$ at time $t=0$:
\begin{align}
N(t)=N_0e^{-\lambda t}
\end{align}
The rate of decays (how many decays we expect per unit time) is simply given by the time derivative (in this case we take the absolute value since we are interested in the rate of change of $N$ and do not explicitly care that it is decreasing):
\begin{align}
\left | \frac{dN}{dt} \right |=\lambda N_0e^{-\lambda t}=\lambda N
\end{align}
In a given time interval, $T$, we thus expect an average of $n$ decays given by:
\begin{align}
n=\lambda N T
\end{align}
$n$ is thus our expected number of decays in a period of time $T$ for a radioactive decay constant $\lambda$ given that we have $N$ un-decayed atoms. We can now use the Poisson probability mass function to evaluate the probability of getting $k$ decays in that period of time. 


\begin{example}{}{A typical germanium detector is made of ultra pure germanium (100\% germanium with a weight per atom of 72.64 atomic mass unit) and has a mass of 1\,kg. We are interested in using a single germanium detector to observe a rare form of radioactive decay called ``double-beta decay''. The decay only occurs for the isotope $^{76}$Ge which has a 7.4\% natural abundance. The half-life of the decay is very long and has been determined to be 1.8$\times$10$^{21}$ years. Due to natural radioactivity in our laboratory, we have a background rate in our germanium detector of 10 counts per month, so we need to make sure that we expect a rate for the radioactive decay that is well above that in order to measure it and justify the expense. What is the probability of observing exactly 15 double-beta decays in our detector if we operate it for 1 month? What is the probability that we will see 15 or more events from double-beta decay?}{}

First we must find out how many $^{76}$Ge are present in our 1\,kg detector. This is given by using the average mass of a germanium atom (72.63\,amu) and the natural abundance. 
\begin{align*}
N_{^{76}Ge}=0.074\frac{1000\,g}{72.63\,amu\times1.66\times10^{-24}\,g/amu}=6.14\times10^{23}
\end{align*}
We must then convert the half-life to a decay rate. The half-life is the time that it takes for half of the atoms to decay, so the radioactive decay law gives:
\begin{align*}
N(t)&=N_0e^{-\lambda t}\\
\therefore \frac{1}{2}N_0&=N_0e^{-\lambda t_{1/2}}\\
\therefore \lambda&=\frac{\ln(2)}{t_{1/2}}=3.85\times 10^{-22}\,yr^{-1}
\end{align*}
The expected number of decays in a 1 month period ($T=1/12$\,years) is given by:
\begin{align*}
n&=N_{^{76}Ge}\lambda T\\
n&=6.14\times10^{23}\times3.85\times 10^{-22}\,yr^{-1}\frac{1\,yr}{12}\\
n&=19.7
\end{align*}
Evaluating the probability from the Poisson distribution with $n=19.7$ and $k=15$ gives 5.6\%.

In order to get the probability of observing 15 or more events, we must sum the Poisson probabilities for $k=15,16,\dots$ to infinity. The infinite sum can be avoided by instead summing the probabilities for $k=0,1,\dots,14$ and subtracting that from 1. The result is that the probability of getting 15 or more decays in 1 month is 88.3\%.

We thus conclude that we have a good (88.3\%) chance to detect double-beta decay given the requirement that we want to see at least 15 counts so that our signal is distinguishable from the background\footnote{In reality, achieving a background rate of 10 counts per month in a germanium detector is very challenging, and it is not nearly as easy to observe double-beta decay.}. The python code below shows how to calculate everything and uses the function \code{sf} to sum the probabilities of obtaining $k=15$ counts or more:
\begin{lstlisting}[frame=single] 
import numpy as np
import scipy.stats as stats # to use Poisson
from math import * # to use log

#Need the number of Ge atoms in 1 kg of germanium
mGe=72.63 #amu
amu=1.66054e-24 #amu to grams
abundance=0.074
mexp=1000 #total mass of Ge in grams
NGe=abundance*mexp/(amu*mGe)
print("There are {:.2e} 76Ge atoms".format(NGe))

#from half-life, need decay rate
thalf=1.8e21 #half-life in years
lam=log(2)/thalf #lambda, but cannot call it lambda as that is a python keyword
rate=NGe*lam
print("Lambda is {:.2e}".format(lam))
print("The decay rate is {:.1f} per year".format(rate))
print("The decay rate is {:.1f} per month".format(rate/12))

n=rate/12 #The expected number of decays in 1 month

print("The prob. of observing exactly 15 decays in one month is: {:.3f}".format(stats.poisson.pmf(15,n)))
#For sf, need k -> k-1 if we want to include k:
print("The prob. of observing 15 or more decays in one month is: {:.3f}".format(stats.poisson.sf(14,n)))
\end{lstlisting}
The output is:
\begin{verbatim}
There are 6.14e+23 76Ge atoms
Lambda is 3.85e-22
The decay rate is 236.3 per year
The decay rate is 19.7 per month
The prob. of observing exactly 15 decays in one month is: 0.056
The prob. of observing 15 or more decays in one month is: 0.883
\end{verbatim}

\end{example}

Figure \ref{fig:poisson} shows the Poisson distribution as a function of $k$ plotted for different values of the expected number of successes, $n$. For low values of $n$, the distribution is asymmetric, but as $n$ becomes bigger, the distribution becomes more symmetric and eventually will approach the normal distribution (discussed in Chapter \ref{chap:StatsNormal}).

\capfig{0.5\textwidth}{figures/poisson.png}{\label{fig:poisson} Poisson distribution for different values of the expected number of successes.}

Figure \ref{fig:poisson_binom} shows a comparison of the Poisson distribution for $n=3$ along with the binomial distribution with different values of $N$ and $p$ such that $Np=3$. As $p$ gets smaller, the binomial distribution is indeed seen to approach the Poisson distribution.

\capfig{0.5\textwidth}{figures/poisson_binom.png}{\label{fig:poisson_binom} Comparison of the Poisson distribution with $n=3$ and the binomial distribution for $Np=3$, using different combination of $N$ and $p$. As $p$ gets smaller, the binomial distribution converges to the Poisson distribution.}

The Poisson distribution is extremely useful and appears every time that one carries out experiments that involve counting. This is because one can phrase any experiment where something is to be counted into a problem of asking: ``what is the probability that I count $k$ occurrences when I expect $n$?''.

For example, what is the chance that 14 babies will be born at the hospital tonight, when on average 10 are born per night? Or, what is the probability that we will have less than 3 accidents this week in Kingston when we usually have 6 accidents per week? Again, all of these scenarios could be modeled by the binomial distribution, but they correspond to cases where $p$ is very small and where the Poisson distribution is much easier to use (the probability of a specific mother giving birth on a given night is relatively small, as is the probability of a specific car getting into an accident).

It can sometimes be difficult to conceptualize a counting experiment with the concept of a probability in a binomial process being small. Usually, the way to think about it is that there is a small probability for a specific item out of many to be the one that is counted, but a finite number of items that will be counted. 

When we count something that has intrinsic randomness (as the examples above), the Poisson distribution can help us to understand the uncertainty on a measured number of counts. Since we understand that when we count something, the result we get follows the Poisson distribution, we can very precisely quantify the probability of getting a number that is bigger or smaller than what we obtained. In fact, we can use the Poisson distribution to define a range in which we are, say, 90\% confident that the true value lies.

\begin{example}{}{Suppose that we spent one week in an all-inclusive vacation in the Caribbean, lounging on the beach and watching tourists get hit on the head by falling coconuts. In one week, we counted that 10 tourists were hit on the head by coconuts. Upon returning to our university, we want to tell our physics professor about our measurement and wish to report with a high degree of confidence (90\%) how many tourists get hit by coconuts every week. What range should we quote?}{}
\label{ex:PoissonCoconut}
Note that this is a Poisson process, and the probability of a specific tourist getting hit by a coconut is small, but the number of tourists that will get hit is finite.

We want to find a range over which the number of coconut hits per week covers 90\% of the probability. For example, we would like to be able to say that we are 90\% confident that every week between 8 and 12 tourists get hit. 

We only have 1 data point, which is the 10 hits that we counted in the week that we were there. Our ``best estimate'' for the expected number of hits each week is thus $n=10$. We can tabulate the Poisson probabilities for $n=10$:

\begin{table}[h!]
\begin{tabular}{|c|c|}
\hline
number of hits & Poisson prob\\
\hline
5 & 0.038 \\
\hline
6 & 0.063 \\
\hline
7 & 0.090 \\
\hline
8 & 0.113 \\
\hline
9 & 0.125 \\
\hline
\cellcolor{gray!25} 10 & \cellcolor{gray!25} 0.125 \\
\hline
11 & 0.114 \\
\hline
12 & 0.095 \\
\hline
13 & 0.073 \\
\hline
14 & 0.052 \\
\hline
15 & 0.035 \\
\hline
16 & 0.022 \\
\hline
\end{tabular}
\caption{Poisson probabilities of the number of tourists getting hit by coconuts in a week for an expected number of 10.}
\end{table}

We can use different ways to choose the range; one way is to symmetrically expand the range on either side of 10 and add the probabilities until we reach 90\%. The following python code does this:
\begin{lstlisting}[frame=single] 
import numpy as np
import scipy.stats as stats # to use Poisson

n=10 # the expected number of coconut hits
#Sum the probabilities on either side of n until we reach 90%
prob=stats.poisson.pmf(n,n)#the probability of getting exactly n
i=0
while(prob<0.9):
    i=i+1
    #add in the probability at n-i and n+i
    prob=prob+stats.poisson.pmf(n-i,n)+stats.poisson.pmf(n+i,n)
    
print("Between {} and {}, the probability is {:.1f}%".format(n-i,n+i,100*prob))
\end{lstlisting}
The output is:
\begin{verbatim}
Between 5 and 15, the probability is 92.2%
\end{verbatim}
Thus, if we observed 10 coconut hits in one week, we can claim with 92.2\% confidence that every week, between 5 and 15 people get hit by coconuts! 

We can also easily modify this code to get the common 68\% confidence level (replace 0.9 in the \code{while} statement with 0.68), in which case we find that with 73.4\% confidence, between 7 and 13 people get hit on the head each week. We could quote that, each week 10 $\pm$ 3 people get hit with coconuts.

If you recall, we had prescribed in Section \ref{sec:countingError} that the uncertainty on a counting measurement should be the square root of the number of counts, and that this would give a 68\% chance that the true number is in the quoted range. We have just verified numerically that this is true, as our square root uncertainty would be $\sqrt{10}=3.2$, close to what we have found. 
\end{example}   

\subsection{Statistical properties of the Poisson distribution}
The mean of measurements that follow the Poisson distribution for an expected number of successes, $n$, is simply $n$:
\begin{align}
\bar k = \sum_{k=0}^{k=\infty}kP^{Poisson}(k,n)=n
\end{align}
and their variance is given by:
\begin{align}
\sigma^2 = \sum_{k=0}^{k=\infty}(k-\bar k)^2P^{Poisson}(k,n)=n
\end{align}

The standard deviation (the square root of the variance) is thus given by $\sqrt{n}$. This is the origin of the prescription for the square root uncertainty presented in Section \ref{sec:countingError}, which as we saw approaches the value of a 68\% confidence when $n$ becomes large (for $n=10$, we saw in example \ref{ex:PoissonCoconut} that the confidence level was approximately 73.4\%).

We can go back to Example \ref{ex:BinomialPhones}, where we had counted the number of students that had checked their phone during the lectures. From the data, we found a mean of 6.1 students checking their phone with a variance of 3.4. If the students checking their phones are binomially distributed, then we expected the variance to be 4.2. Now that we know the variance for a Poisson process, we can see if the students are closer to that distribution. The expected number, $n$, for the Poisson process is also 6.1 (it is equal to the mean of the binomial). The expected variance, if the process of student checking their phones is Poisson, is thus also 6.1. We can see that, in this case, the data (based on their variance) are more consistent with the binomial distribution than the Poisson distribution.

One other interesting property of the Poisson distribution is that if you measure the time interval between two events, the distribution of those times will follow a decaying exponential. That is, you will more often have two Poisson events that follow each other close in time, rather than having a long time between events. For example, if you look at radioactive decays and measure the time between two decays, you will find that two decays happen in rapid succession more often than with a long time interval. A more tangible example is that airplane crashes seem to appear in bunches rather than spread out regularly over time. This is because airplane crashes are rare (Poisson) events, so it is in fact more likely to have them occur closely in time rather than regularly spread out over the year. A mis-understanding of Poisson statistics also leads to people predicting impeding doomsdays when ``terrible'' events happen in close succession: it is in fact more likely for several terrible events to happen in close succession than evenly spread apart. 

\section{Statistical hypothesis testing}
We can now apply our understanding of distributions to statistical hypothesis testing. The general idea is that given the result of a measurement, we want to be able to make a quantitative statement about how likely the result is based on a hypothesis. If the result is very unlikely according to the hypothesis, then we would conclude that the hypothesis is not supported by the data. 

For example, a pharmaceutical company may claim that they have developed a new pill that can help people to perform very well on IQ tests . As sceptical scientists, we decide to test whether the pill is actually effective and devise the following test: we choose 16 people, give them a first IQ test, then give them the pill, and finally give them a second, different but equivalent, IQ test. Suppose that we find that 10 out of the 16 people have performed ``significantly'' better on the second IQ test; can we conclude that the pill works?

We need to state this problem into a hypothesis that predicts the distribution of outcomes, and then evaluate the probability of our outcome (10 out 16 people performing better). If the probability is high, then the hypothesis is supported (note that it is never proven). When possible, one should try to make a ``null hypothesis'', which is usually easier to model. Typically, the null hypothesis is that ``there is no effect'', and the results are the outcome of chance.

In our case, our null hypothesis is that the pill has no effect, or rather that the results are from pure chance. We must thus ask ourselves what is the probability that, out of pure chance, 10 out 16 participants would perform better on a second IQ test? If we imagine that the IQ tests have many questions, it is unlikely that someone would get exactly the same score twice in a row. It seems reasonable that it is equally likely that they will perform a little better or a little worse on the second test. Let us thus assume that there is a 50\% chance that they will perform a little bit better just from pure chance.

We can model our experiment as a binomial problem: we have 16 people ($N$ trials), and we had 10 people do better on the second test ($k$ successes), and under our null hypothesis there is a 50\% chance of performing better on the second test ($p$). The binomial probability, $P^{binom}(k=10,N=16,p=0.5)$ is easily found to be 12\%. There is thus a 12\% chance that exactly 10 out 16 people would do better on the IQ test out of chance.

However, this null hypothesis does not quite cover the possibility that 11 (or 12, or more) people could have done better on the test. The better (and correct) question to ask is, what is the probability that 10 \textbf{or more} people out of 16 scored better on the test out of pure chance? We thus need to sum the binomial probabilities corresponding to the possibilities of 10 or more successes. If we sum those probabilities for $k=10, 11, \dots, 16$, with $N=16$ and $p=0.5$, we find that the probability of 10 or more people doing better on the test, out of pure chance, is 23\%.

Is 23\% a high enough probability for us to support the null hypothesis that the results are from pure chance? Of course, that is an arbitrary question. One way to think about whether a probability is ``high'' is to ask yourself if you would risk your life at that probability. Would you get in a car if you knew you had a 23\% chance of getting into a fatal accident? Probably not (I hope). At 23\%, we would generally accept the null hypothesis as plausible, and conclude that the results are consistent with pure chance. In science, a common ``bar'' is that the null hypothesis must be no more than 5\% plausible for it to be rejected, although depending on how ``revolutionary'' the result, that bar can be much higher. For example, for discovering a new particle in physics, the null hypothesis (there is no new particle) must usually be no more than 0.00006\% likely. It is a somewhat accepted practice to call a result ``significant'' if the null hypothesis is no more than 5\% probable, and ``highly significant'' if the null hypothesis is no more than 1\% probable.

Why would we not think about this the other way around, namely that the hypothesis that the pill works is confirmed with 77\% probability (100-23), well exceeding our 5\% bar? Remember, our model is that there is a 50\% chance of doing better on an IQ test simply due to chance. Our model is not ``given this pill, there is a x\% chance of doing better on the test''. The 77\% probability cannot be interpreted as the probability that the pill works, which would be a completely different hypothesis. The ``opposite'' of ``the results are from pure chance'' is \textit{not} that ``the pill works''. Perhaps there are other effects (other than chance) that lead to our result that are not the pill itself (maybe the subjects took the pill with some water, were then better hydrated, and performed better, or it was a placebo effect). 

We did not quite analyse our data correctly, since we earlier claimed that 10 of the test subjects performed \textit{significantly} better, not just marginally better. The definition of ``significantly'' would presumably come from the designers of the IQ test. IQ tests are statistical tests in themselves, so let us assume that if someone gets a score of $X$, then the test is designed such that one can attribute an uncertainty to the score, $\delta X$, such that over repeated tests, there is a 68\% chance that a given participant scores in the range $X \pm \delta X$. When we claimed that 10 of the test subjects performed significantly better, we really meant that they performed with a score higher than their original score plus the uncertainty.

To take this into account, we must thus use a different probability than $p=0.5$ in our null hypothesis that subjects would perform significantly better just out of pure chance. In this case, out of pure chance, there is a 32\% (100-68) chance of a participant scoring outside of the range $X \pm \delta X$, and a 50\% probability that it is on the higher side of the range. The correct binomial probability to use is thus $p=0.5\times 0.32=0.16$, and it represents the probability of scoring significantly higher out of pure chance. Evaluating the sum of the probabilities $P^{binom}(k,N=16,p=0.16)$ for $k=10, 11, \dots, 16$ gives 0.0034\%, which is certainly low. It is thus unlikely that the null hypothesis is correct, in other words, it is unlikely that by pure chance 10 or more out of 16 participants would score significantly higher on the IQ test. We would then lean to the conclusion that the pill likely has some effect (but as good scientists, we would want to make sure that any other possible effect have been controlled in the test; for example, that there is no placebo effect from the pill, that the water taken with the pill had no effect, etc.).

The python code below shows how to calculate the probabilities for this example.
\begin{lstlisting}[frame=single] 
import scipy.stats as stats # to use Poisson

#Probability of 10 out of 16 people doing better on IQ test if the probability of doing better is 50%:
print("Prob that 10 out 16 people do a little better:{:.2f}".format(stats.binom.pmf(10,16,0.5)))
print("Prob that at least 10 out 16 people do a little better:{:.2f}".format(stats.binom.sf(9,16,0.5)))

#Probability of 10 out of 16 people doing better on IQ test if the probability of doing better is 16%:
print("Prob that 10 out 16 people do significantly better:{:.6f}".format(stats.binom.pmf(10,16,0.16)))
print("Prob that at least 10 out 16 people do significantly better:{:.6f}".format(stats.binom.sf(9,16,0.16)))
\end{lstlisting}
The output is:
\begin{verbatim}
Prob that 10 out 16 people do a little better:0.12
Prob that at least 10 out 16 people do a little better:0.23
Prob that 10 out 16 people do significantly better:0.000031
Prob that at least 10 out 16 people do significantly better:0.000034
\end{verbatim}

\begin{example}{}{The 2013 Ontario Road Safety Annual Report shows the following number of fatal car collisions by month: \{35,17,26,24,39,27,61,44,37,46,42,31\}, which add up to 429 for the year. Upon looking at the data, a politician decides that their next campaign will be based on banning driving in July since that is a particularly deadly month for driving in Ontario (61 deaths). Can you support the politician's claim that July is a bad month for driving?}{}
We must first develop a null hypothesis, namely that no month is particularly worse for driving. If the data are consistent with the null hypothesis, then there is little reason to support the politician's claim. We thus need to evaluate the probability of having 61 or more fatal accidents in a particular month under the hypothesis that all months are equal. 

In our null hypothesis, we expect the rate of accidents each month to be approximately equal to the average rate. Since we had 429 accidents in the year, we would expect 429/12=36 accidents per month as the average rate. Given that we expect 36 accidents in a month under the null hypothesis, what is the probability of having 61 or more accidents? This is found using the Poisson distribution, $P^{Poisson}(k,n)$. In the Poisson distribution, the value of $k$ can go up to infinity, so it is not practical to sum the probabilities from $k=61, 62, \dots, \infty$. It is easiest to simply use the cumulative probability distribution, which is the sum of the probabilities from $k=0, 1, \dots, 61$, and then subtract that from 1.  Evaluating the cumulative distribution and subtracting it from 1, we find that the probability of having 61 or more accidents, when we expect 36, is 0.0091\%, which is certainly small. The null hypothesis is not supported by the data, so we conclude that it is highly likely that some months (July in particular) are more fatal than others on Ontario roads, based on the 2013 data.

As good scientists, we would still want to look at the data from other years to see if they also do not support the null hypothesis. In 2012, there were a total of 505 accidents in the year (an expected 42 accidents per month), and 50 accidents in July. Going through the same exercise, gives the probability for there to be 50 or more accidents in a month, when we expect 42, to be 12.5\%, which is orders of magnitude higher than 2013 and well above our 5\% bar (if that is the bar that we choose). As you can see, you need to be very careful when making claims based on statistical data, and some arbitrary bar!

The code below shows how to calculate the relevant probabilities in python (using the survival fraction):
\begin{lstlisting}[frame=single] 
import scipy.stats as stats # to use Poisson

#Probability of having 61 accidents in a month when we expect 36:
print("Prob of 61 accidents when we expect 36:{:.6f}".format(stats.poisson.pmf(61,36)))
print("Prob of at least 61 accidents when we expect 36:{:.6f}".format(stats.poisson.sf(60,36)))

#Probability of having 50 accidents in a month when we expect 42:
print("Prob of 50 accidents when we expect 42:{:.4f}".format(stats.poisson.pmf(50,42)))
print("Prob of 50 accidents when we expect 42:{:.4f}".format(stats.poisson.sf(49,42)))
\end{lstlisting}
The output is:
\begin{verbatim}
Prob of 61 accidents when we expect 36:0.000039
Prob of at least 61 accidents when we expect 36:0.000091
Prob of 50 accidents when we expect 42:0.0275
Prob of 50 accidents when we expect 42:0.1250
\end{verbatim}
\end{example}


\section{Summary}
In this chapter, we introduced the concept of a statistical distribution to model the spread of results that arises from processes that have some randomness associated with them. We introduced the binomial distribution to model processes where we expect $k$ successes after $N$ independent trials, when a given success has a probability of $p$. The binomial distribution gives the probability of having exactly $k$ successes, and the probability mass function is given by:
\begin{align}
P^{binom}(k,N,p)=\frac{N!}{k!(N-k)!}p^k(1-p)^{N-k}
\end{align}
The mean and variance of a quantity that is binomially distributed are given by:
\begin{align}
\bar k &= \sum_{k=0}^{k=N}kP^{binom}(k,N,p)=Np\\
\sigma^2 &= \sum_{k=0}^{k=N}(k-\bar k)P^{binom}(k,N,p)=Np(1-p)
\end{align}

We then introduced the Poisson distribution to model the probability of obtaining $k$ successes when we expect $n$. We saw that the Poisson distribution is the limiting case of the binomial distribution when $n=Np$ and $p$ is small (thus the probability of a particular success is low, but the total number of successes is finite). The Poisson distribution probability mass function is given by:
\begin{align*}
 P^{Poisson}(k,n)=\frac{n^k e^{-n}}{k!} 
\end{align*}  
The mean and variance of a quantity that is Poisson distributed are given by:
\begin{align}
\bar k &= \sum_{k=0}^{k=\infty}kP^{Poisson}(k,n)=n\\
\sigma^2 &= \sum_{k=0}^{k=\infty}(k-\bar k)P^{Poisson}(k,n)=n
\end{align}
The variance of the Poisson distribution is equal to its mean, $n$. The standard deviation is thus $\sqrt{n}$, which is the origin of the square root uncertainty in counted quantity.

Finally, we introduced the concept of statistical hypothesis testing, which involved determining the probability of a particular outcome given a particular hypothesis. We argued that it is usually easier to model the null hypothesis, that is, to determine the probability of the results occurring out of pure chance. We cautioned against drawing conclusions simply based on the probability of the null hypothesis being below a given bar (5\% is often used). Generally, the null hypothesis is of the form: ``what is the probability of getting x or more successes out of pure chance?''.